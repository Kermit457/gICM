{"version":3,"sources":["../src/decision-agent.ts","../src/types.ts","../src/prompts.ts","../src/scorer.ts"],"sourcesContent":["import { BaseAgent } from \"@gicm/agent-core\";\nimport type { AgentConfig, AgentContext, AgentResult } from \"@gicm/agent-core\";\nimport type { HuntDiscovery } from \"@gicm/hunter-agent\";\nimport { DecisionScorer, type ScorerConfig } from \"./scorer.js\";\nimport type { DecisionResult, DecisionStatus, DecisionThresholds } from \"./types.js\";\nimport { DEFAULT_THRESHOLDS } from \"./types.js\";\n\nexport interface DecisionAgentConfig extends AgentConfig {\n  llmProvider: \"openai\" | \"anthropic\" | \"gemini\";\n  apiKey: string;\n  model?: string;\n  thresholds?: DecisionThresholds;\n  onDecision?: (\n    discovery: HuntDiscovery,\n    result: DecisionResult,\n    status: DecisionStatus\n  ) => Promise<void>;\n}\n\nexport interface ScoredDiscovery {\n  discovery: HuntDiscovery;\n  result: DecisionResult;\n  status: DecisionStatus;\n}\n\nexport class DecisionAgent extends BaseAgent {\n  private scorer: DecisionScorer;\n  private thresholds: DecisionThresholds;\n  private onDecision?: DecisionAgentConfig[\"onDecision\"];\n\n  constructor(config: DecisionAgentConfig) {\n    super(\"decision\", config);\n\n    this.thresholds = config.thresholds ?? DEFAULT_THRESHOLDS;\n    this.onDecision = config.onDecision;\n\n    const scorerConfig: ScorerConfig = {\n      llmProvider: config.llmProvider,\n      apiKey: config.apiKey,\n      model: config.model,\n      thresholds: this.thresholds,\n    };\n\n    this.scorer = new DecisionScorer(scorerConfig);\n  }\n\n  getSystemPrompt(): string {\n    return `You are a decision engine for gICM Orchestrator.\nYour role is to evaluate discoveries and determine:\n1. Should we act on this? (score 0-100)\n2. What action should we take? (build/integrate/monitor/ignore)\n3. What are the risks?\n4. How much effort is required?\n\nAuto-approve if score >= ${this.thresholds.autoApprove}\nQueue for human review if score >= ${this.thresholds.humanReview}\nAuto-reject if score < ${this.thresholds.humanReview}`;\n  }\n\n  async analyze(context: AgentContext): Promise<AgentResult> {\n    const action = context.action ?? \"evaluate\";\n\n    switch (action) {\n      case \"evaluate\":\n        return this.evaluateDiscovery(context.params?.discovery as HuntDiscovery);\n\n      case \"evaluate_batch\":\n        return this.evaluateBatch(context.params?.discoveries as HuntDiscovery[]);\n\n      case \"status\":\n        return this.createResult(\n          true,\n          {\n            thresholds: this.thresholds,\n            provider: (this.config as DecisionAgentConfig).llmProvider,\n          },\n          undefined,\n          1.0,\n          \"Decision agent status\"\n        );\n\n      default:\n        return this.createResult(false, null, `Unknown action: ${action}`);\n    }\n  }\n\n  async evaluate(discovery: HuntDiscovery): Promise<ScoredDiscovery> {\n    this.log(`Evaluating: ${discovery.title}`);\n\n    const result = await this.scorer.evaluate(discovery);\n    const status = this.scorer.determineStatus(result.totalScore);\n\n    this.log(\n      `Score: ${result.totalScore}/100 | Status: ${status} | Recommendation: ${result.recommendation}`\n    );\n\n    // Notify callback if provided\n    if (this.onDecision) {\n      await this.onDecision(discovery, result, status);\n    }\n\n    return { discovery, result, status };\n  }\n\n  async evaluateMany(discoveries: HuntDiscovery[]): Promise<ScoredDiscovery[]> {\n    this.log(`Evaluating ${discoveries.length} discoveries`);\n\n    const results: ScoredDiscovery[] = [];\n\n    for (const discovery of discoveries) {\n      const scored = await this.evaluate(discovery);\n      results.push(scored);\n    }\n\n    // Sort by score descending\n    results.sort((a, b) => b.result.totalScore - a.result.totalScore);\n\n    const approved = results.filter((r) => r.status === \"auto_approve\").length;\n    const review = results.filter((r) => r.status === \"human_review\").length;\n    const rejected = results.filter((r) => r.status === \"reject\").length;\n\n    this.log(\n      `Results: ${approved} auto-approved, ${review} for review, ${rejected} rejected`\n    );\n\n    return results;\n  }\n\n  private async evaluateDiscovery(\n    discovery: HuntDiscovery | undefined\n  ): Promise<AgentResult> {\n    if (!discovery) {\n      return this.createResult(false, null, \"No discovery provided\");\n    }\n\n    try {\n      const scored = await this.evaluate(discovery);\n\n      return this.createResult(\n        true,\n        scored,\n        undefined,\n        scored.result.confidence,\n        `Evaluated \"${discovery.title}\": ${scored.result.totalScore}/100 (${scored.status})`\n      );\n    } catch (error) {\n      const message = error instanceof Error ? error.message : \"Unknown error\";\n      return this.createResult(false, null, message);\n    }\n  }\n\n  private async evaluateBatch(\n    discoveries: HuntDiscovery[] | undefined\n  ): Promise<AgentResult> {\n    if (!discoveries || discoveries.length === 0) {\n      return this.createResult(false, null, \"No discoveries provided\");\n    }\n\n    try {\n      const results = await this.evaluateMany(discoveries);\n\n      const summary = {\n        total: results.length,\n        autoApproved: results.filter((r) => r.status === \"auto_approve\"),\n        forReview: results.filter((r) => r.status === \"human_review\"),\n        rejected: results.filter((r) => r.status === \"reject\"),\n        topDiscoveries: results.slice(0, 5),\n      };\n\n      return this.createResult(\n        true,\n        summary,\n        undefined,\n        0.9,\n        `Evaluated ${results.length} discoveries: ${summary.autoApproved.length} auto-approved, ${summary.forReview.length} for review`\n      );\n    } catch (error) {\n      const message = error instanceof Error ? error.message : \"Unknown error\";\n      return this.createResult(false, null, message);\n    }\n  }\n\n  // Convenience methods for filtering\n  getAutoApproved(results: ScoredDiscovery[]): ScoredDiscovery[] {\n    return results.filter((r) => r.status === \"auto_approve\");\n  }\n\n  getForReview(results: ScoredDiscovery[]): ScoredDiscovery[] {\n    return results.filter((r) => r.status === \"human_review\");\n  }\n\n  getRejected(results: ScoredDiscovery[]): ScoredDiscovery[] {\n    return results.filter((r) => r.status === \"reject\");\n  }\n\n  // Update thresholds dynamically\n  setThresholds(thresholds: Partial<DecisionThresholds>): void {\n    this.thresholds = { ...this.thresholds, ...thresholds };\n    this.log(`Updated thresholds: ${JSON.stringify(this.thresholds)}`);\n  }\n}\n","import { z } from \"zod\";\n\n// Decision scores\nexport const DecisionScoresSchema = z.object({\n  relevance: z.number().min(0).max(100),\n  impact: z.number().min(0).max(100),\n  effort: z.number().min(0).max(100), // Higher = easier\n  timing: z.number().min(0).max(100),\n  quality: z.number().min(0).max(100),\n});\nexport type DecisionScores = z.infer<typeof DecisionScoresSchema>;\n\n// Role Storming verdicts\nexport const PersonaVerdictSchema = z.enum([\"approve\", \"reject\", \"cautious\"]);\nexport type PersonaVerdict = z.infer<typeof PersonaVerdictSchema>;\n\nexport const RoleStormingConsensusSchema = z.enum([\n  \"strong_approve\",\n  \"approve\",\n  \"mixed\",\n  \"reject\",\n  \"strong_reject\",\n]);\nexport type RoleStormingConsensus = z.infer<typeof RoleStormingConsensusSchema>;\n\nexport const PersonaEvaluationSchema = z.object({\n  verdict: PersonaVerdictSchema,\n  reasoning: z.string(),\n});\nexport type PersonaEvaluation = z.infer<typeof PersonaEvaluationSchema>;\n\nexport const RoleStormingResultSchema = z.object({\n  conservative: PersonaEvaluationSchema,\n  degen: PersonaEvaluationSchema,\n  whale: PersonaEvaluationSchema,\n  skeptic: PersonaEvaluationSchema,\n  builder: PersonaEvaluationSchema,\n  consensus: RoleStormingConsensusSchema,\n});\nexport type RoleStormingResult = z.infer<typeof RoleStormingResultSchema>;\n\n// Decision recommendation\nexport const RecommendationSchema = z.enum([\n  \"build\",      // Create new component/agent based on this\n  \"integrate\",  // Integrate this tool/library directly\n  \"monitor\",    // Keep watching, not ready yet\n  \"ignore\",     // Not relevant or too risky\n]);\nexport type Recommendation = z.infer<typeof RecommendationSchema>;\n\n// Decision result\nexport const DecisionResultSchema = z.object({\n  scores: DecisionScoresSchema,\n  roleStorming: RoleStormingResultSchema.optional(),\n  totalScore: z.number().min(0).max(100),\n  recommendation: RecommendationSchema,\n  reasoning: z.string(),\n  summary: z.string(),\n  suggestedAction: z.string(),\n  tags: z.array(z.string()),\n  riskLevel: z.enum([\"low\", \"medium\", \"high\", \"critical\"]),\n  riskFactors: z.array(z.string()),\n  estimatedEffort: z.string(),\n  confidence: z.number().min(0).max(1),\n});\nexport type DecisionResult = z.infer<typeof DecisionResultSchema>;\n\n// Thresholds for autonomy levels\nexport interface DecisionThresholds {\n  autoApprove: number;   // Score >= this: auto-approve\n  humanReview: number;   // Score >= this: queue for review\n  // Below humanReview: auto-reject\n}\n\nexport const DEFAULT_THRESHOLDS: DecisionThresholds = {\n  autoApprove: 85,\n  humanReview: 50,\n};\n\n// Decision status\nexport type DecisionStatus = \"auto_approve\" | \"human_review\" | \"reject\";\n\n// LLM response schema\nexport const LLMDecisionResponseSchema = z.object({\n  scores: z.object({\n    relevance: z.object({\n      score: z.number(),\n      reasoning: z.string(),\n    }),\n    impact: z.object({\n      score: z.number(),\n      reasoning: z.string(),\n    }),\n    effort: z.object({\n      score: z.number(),\n      reasoning: z.string(),\n    }),\n    timing: z.object({\n      score: z.number(),\n      reasoning: z.string(),\n    }),\n    quality: z.object({\n      score: z.number(),\n      reasoning: z.string(),\n    }),\n  }),\n  roleStorming: RoleStormingResultSchema.optional(),\n  totalScore: z.number(),\n  recommendation: RecommendationSchema,\n  reasoning: z.string(),\n  summary: z.string(),\n  suggestedAction: z.string(),\n  tags: z.array(z.string()),\n  riskLevel: z.enum([\"low\", \"medium\", \"high\", \"critical\"]),\n  riskFactors: z.array(z.string()),\n  estimatedEffort: z.string(),\n  confidence: z.number(),\n});\nexport type LLMDecisionResponse = z.infer<typeof LLMDecisionResponseSchema>;\n\n// Scoring weights\nexport const SCORING_WEIGHTS = {\n  relevance: 0.30,\n  impact: 0.25,\n  effort: 0.20,\n  timing: 0.15,\n  quality: 0.10,\n} as const;\n","import type { HuntDiscovery } from \"@gicm/hunter-agent\";\n\nexport const SYSTEM_PROMPT = `You are a technical opportunity evaluator for gICM, a Web3/AI development platform.\n\nYour role is to evaluate discoveries (GitHub repos, HackerNews posts, Twitter discussions) and determine their value to the gICM ecosystem.\n\ngICM focuses on:\n- Web3/Blockchain development tools (especially Solana and Ethereum)\n- AI agents and LLM-powered tools\n- Developer tooling and productivity\n- DeFi protocols and integrations\n- NFT and DAO tooling\n\n## Role Storming Evaluation\n\nYou MUST evaluate each discovery from 5 distinct persona perspectives:\n\nðŸ‘¤ **The Conservative Investor**\n   Focus: Capital preservation, proven track record, established teams\n   Questions: Is the team reputable? Is there existing traction? What's the downside risk?\n\nðŸ‘¤ **The Aggressive Degen**\n   Focus: Maximum upside potential, early entry advantage, high-risk/high-reward\n   Questions: Could this 10x? Are we early enough? What's the alpha here?\n\nðŸ‘¤ **The Whale**\n   Focus: Scalability, market impact, liquidity implications\n   Questions: Can this scale? Does it move markets? Is there enough depth?\n\nðŸ‘¤ **The Skeptic**\n   Focus: Red flags, team quality, potential failure modes\n   Questions: What could go wrong? Is this vaporware? Where's the catch?\n\nðŸ‘¤ **The Builder**\n   Focus: Technical quality, code architecture, product-market fit\n   Questions: Is the code solid? Does it solve a real problem? Can we integrate it?\n\nBe decisive and score conservatively. Only truly exceptional discoveries should exceed 85/100.\n\nOutput your evaluation as valid JSON matching this schema:\n{\n  \"scores\": {\n    \"relevance\": { \"score\": 0-100, \"reasoning\": \"...\" },\n    \"impact\": { \"score\": 0-100, \"reasoning\": \"...\" },\n    \"effort\": { \"score\": 0-100, \"reasoning\": \"...\" },\n    \"timing\": { \"score\": 0-100, \"reasoning\": \"...\" },\n    \"quality\": { \"score\": 0-100, \"reasoning\": \"...\" }\n  },\n  \"roleStorming\": {\n    \"conservative\": { \"verdict\": \"approve\" | \"reject\" | \"cautious\", \"reasoning\": \"...\" },\n    \"degen\": { \"verdict\": \"approve\" | \"reject\" | \"cautious\", \"reasoning\": \"...\" },\n    \"whale\": { \"verdict\": \"approve\" | \"reject\" | \"cautious\", \"reasoning\": \"...\" },\n    \"skeptic\": { \"verdict\": \"approve\" | \"reject\" | \"cautious\", \"reasoning\": \"...\" },\n    \"builder\": { \"verdict\": \"approve\" | \"reject\" | \"cautious\", \"reasoning\": \"...\" },\n    \"consensus\": \"strong_approve\" | \"approve\" | \"mixed\" | \"reject\" | \"strong_reject\"\n  },\n  \"totalScore\": 0-100,\n  \"recommendation\": \"build\" | \"integrate\" | \"monitor\" | \"ignore\",\n  \"reasoning\": \"Overall analysis\",\n  \"summary\": \"One sentence summary\",\n  \"suggestedAction\": \"What gICM should do\",\n  \"tags\": [\"relevant\", \"tags\"],\n  \"riskLevel\": \"low\" | \"medium\" | \"high\" | \"critical\",\n  \"riskFactors\": [\"list of risks\"],\n  \"estimatedEffort\": \"e.g., '2-3 days', '1 week'\",\n  \"confidence\": 0.0-1.0\n}`;\n\nexport function buildEvaluationPrompt(discovery: HuntDiscovery): string {\n  const metricsStr = Object.entries(discovery.metrics)\n    .filter(([, v]) => v !== undefined)\n    .map(([k, v]) => `${k}: ${v}`)\n    .join(\", \");\n\n  const factorsStr = Object.entries(discovery.relevanceFactors)\n    .filter(([, v]) => v === true)\n    .map(([k]) => k.replace(/^has/, \"\").replace(/Keywords$/, \"\"))\n    .join(\", \");\n\n  return `Evaluate this discovery:\n\n**Source:** ${discovery.source}\n**Title:** ${discovery.title}\n**URL:** ${discovery.sourceUrl}\n**Description:** ${discovery.description ?? \"No description\"}\n**Author:** ${discovery.author ?? \"Unknown\"}\n**Category:** ${discovery.category ?? \"unknown\"}\n**Language:** ${discovery.language ?? \"unknown\"}\n**Tags:** ${discovery.tags.join(\", \") || \"none\"}\n\n**Metrics:**\n${metricsStr || \"No metrics available\"}\n\n**Pre-computed Relevance Factors:**\n${factorsStr || \"None detected\"}\n\n**Published:** ${discovery.publishedAt?.toISOString() ?? \"Unknown\"}\n**Discovered:** ${discovery.discoveredAt.toISOString()}\n\nScoring Criteria:\n1. **Relevance (30%)**: How relevant is this to gICM's focus on Web3/AI development?\n2. **Impact (25%)**: What's the potential value if we act on this discovery?\n3. **Effort (20%)**: How easy to integrate? (100 = trivial, 0 = extremely complex)\n4. **Timing (15%)**: Is this trending? Fresh? Time-sensitive opportunity?\n5. **Quality (10%)**: Code/content quality signals?\n\nOutput your evaluation as JSON.`;\n}\n\nexport function buildBatchEvaluationPrompt(\n  discoveries: HuntDiscovery[]\n): string {\n  const discoveriesText = discoveries\n    .map((d, i) => {\n      const metrics = Object.entries(d.metrics)\n        .filter(([, v]) => v !== undefined)\n        .map(([k, v]) => `${k}:${v}`)\n        .join(\" \");\n\n      return `[${i + 1}] ${d.source} | ${d.title}\n   URL: ${d.sourceUrl}\n   ${d.description?.slice(0, 200) ?? \"No description\"}\n   Metrics: ${metrics}\n   Category: ${d.category ?? \"unknown\"}`;\n    })\n    .join(\"\\n\\n\");\n\n  return `Evaluate these ${discoveries.length} discoveries and rank them by potential value to gICM:\n\n${discoveriesText}\n\nFor EACH discovery, provide scores and recommendation.\nThen rank them from most to least valuable.\n\nOutput as JSON array with the same schema as single evaluations.`;\n}\n","import type { HuntDiscovery } from \"@gicm/hunter-agent\";\nimport {\n  DEFAULT_THRESHOLDS,\n  type DecisionResult,\n  type DecisionScores,\n  type DecisionStatus,\n  type DecisionThresholds,\n  LLMDecisionResponseSchema,\n  type Recommendation,\n  SCORING_WEIGHTS,\n} from \"./types.js\";\nimport { buildEvaluationPrompt, SYSTEM_PROMPT } from \"./prompts.js\";\n\nexport interface ScorerConfig {\n  llmProvider: \"openai\" | \"anthropic\" | \"gemini\";\n  apiKey: string;\n  model?: string;\n  thresholds?: DecisionThresholds;\n}\n\nexport class DecisionScorer {\n  private config: ScorerConfig;\n  private thresholds: DecisionThresholds;\n\n  constructor(config: ScorerConfig) {\n    this.config = config;\n    this.thresholds = config.thresholds ?? DEFAULT_THRESHOLDS;\n  }\n\n  async evaluate(discovery: HuntDiscovery): Promise<DecisionResult> {\n    const prompt = buildEvaluationPrompt(discovery);\n\n    try {\n      const response = await this.callLLM(prompt);\n      const parsed = this.parseResponse(response);\n      return this.validateAndNormalize(parsed);\n    } catch (error) {\n      // Fallback to heuristic scoring if LLM fails\n      console.warn(\"[DecisionScorer] LLM evaluation failed, using heuristics:\", error);\n      return this.heuristicScore(discovery);\n    }\n  }\n\n  async evaluateBatch(\n    discoveries: HuntDiscovery[]\n  ): Promise<Map<string, DecisionResult>> {\n    const results = new Map<string, DecisionResult>();\n\n    // Evaluate in parallel with rate limiting\n    const batchSize = 5;\n    for (let i = 0; i < discoveries.length; i += batchSize) {\n      const batch = discoveries.slice(i, i + batchSize);\n      const evaluations = await Promise.all(\n        batch.map((d) => this.evaluate(d).then((r) => [d.id, r] as const))\n      );\n\n      for (const [id, result] of evaluations) {\n        results.set(id, result);\n      }\n    }\n\n    return results;\n  }\n\n  determineStatus(score: number): DecisionStatus {\n    if (score >= this.thresholds.autoApprove) return \"auto_approve\";\n    if (score >= this.thresholds.humanReview) return \"human_review\";\n    return \"reject\";\n  }\n\n  private async callLLM(prompt: string): Promise<string> {\n    switch (this.config.llmProvider) {\n      case \"openai\":\n        return this.callOpenAI(prompt);\n      case \"anthropic\":\n        return this.callAnthropic(prompt);\n      case \"gemini\":\n        return this.callGemini(prompt);\n      default:\n        throw new Error(`Unknown LLM provider: ${this.config.llmProvider}`);\n    }\n  }\n\n  private async callOpenAI(prompt: string): Promise<string> {\n    const response = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        Authorization: `Bearer ${this.config.apiKey}`,\n      },\n      body: JSON.stringify({\n        model: this.config.model ?? \"gpt-4o-mini\",\n        messages: [\n          { role: \"system\", content: SYSTEM_PROMPT },\n          { role: \"user\", content: prompt },\n        ],\n        response_format: { type: \"json_object\" },\n        temperature: 0.3,\n      }),\n    });\n\n    if (!response.ok) {\n      throw new Error(`OpenAI API error: ${response.status}`);\n    }\n\n    const data = await response.json();\n    return data.choices[0]?.message?.content ?? \"\";\n  }\n\n  private async callAnthropic(prompt: string): Promise<string> {\n    const response = await fetch(\"https://api.anthropic.com/v1/messages\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"x-api-key\": this.config.apiKey,\n        \"anthropic-version\": \"2023-06-01\",\n      },\n      body: JSON.stringify({\n        model: this.config.model ?? \"claude-3-haiku-20240307\",\n        max_tokens: 2048,\n        system: SYSTEM_PROMPT,\n        messages: [{ role: \"user\", content: prompt }],\n      }),\n    });\n\n    if (!response.ok) {\n      throw new Error(`Anthropic API error: ${response.status}`);\n    }\n\n    const data = await response.json();\n    return data.content[0]?.text ?? \"\";\n  }\n\n  private async callGemini(prompt: string): Promise<string> {\n    const model = this.config.model ?? \"gemini-1.5-flash\";\n    const url = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${this.config.apiKey}`;\n\n    const response = await fetch(url, {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify({\n        contents: [\n          {\n            parts: [{ text: `${SYSTEM_PROMPT}\\n\\n${prompt}` }],\n          },\n        ],\n        generationConfig: {\n          temperature: 0.3,\n          responseMimeType: \"application/json\",\n        },\n      }),\n    });\n\n    if (!response.ok) {\n      throw new Error(`Gemini API error: ${response.status}`);\n    }\n\n    const data = await response.json();\n    return data.candidates[0]?.content?.parts[0]?.text ?? \"\";\n  }\n\n  private parseResponse(response: string): DecisionResult {\n    // Extract JSON from response\n    let jsonStr = response;\n\n    // Try to extract from code blocks\n    const codeBlockMatch = response.match(/```(?:json)?\\s*([\\s\\S]*?)```/);\n    if (codeBlockMatch) {\n      jsonStr = codeBlockMatch[1].trim();\n    }\n\n    // Try to find JSON object\n    const jsonMatch = jsonStr.match(/\\{[\\s\\S]*\\}/);\n    if (jsonMatch) {\n      jsonStr = jsonMatch[0];\n    }\n\n    const parsed = JSON.parse(jsonStr);\n    const validated = LLMDecisionResponseSchema.parse(parsed);\n\n    return {\n      scores: {\n        relevance: validated.scores.relevance.score,\n        impact: validated.scores.impact.score,\n        effort: validated.scores.effort.score,\n        timing: validated.scores.timing.score,\n        quality: validated.scores.quality.score,\n      },\n      roleStorming: validated.roleStorming,\n      totalScore: validated.totalScore,\n      recommendation: validated.recommendation,\n      reasoning: validated.reasoning,\n      summary: validated.summary,\n      suggestedAction: validated.suggestedAction,\n      tags: validated.tags,\n      riskLevel: validated.riskLevel,\n      riskFactors: validated.riskFactors,\n      estimatedEffort: validated.estimatedEffort,\n      confidence: validated.confidence,\n    };\n  }\n\n  private validateAndNormalize(result: DecisionResult): DecisionResult {\n    // Recalculate total score with weights\n    const calculatedTotal =\n      result.scores.relevance * SCORING_WEIGHTS.relevance +\n      result.scores.impact * SCORING_WEIGHTS.impact +\n      result.scores.effort * SCORING_WEIGHTS.effort +\n      result.scores.timing * SCORING_WEIGHTS.timing +\n      result.scores.quality * SCORING_WEIGHTS.quality;\n\n    // Use average of LLM total and calculated total\n    const normalizedTotal = Math.round(\n      (result.totalScore + calculatedTotal) / 2\n    );\n\n    return {\n      ...result,\n      totalScore: Math.min(100, Math.max(0, normalizedTotal)),\n    };\n  }\n\n  // Fallback heuristic scoring when LLM is unavailable\n  private heuristicScore(discovery: HuntDiscovery): DecisionResult {\n    const factors = discovery.relevanceFactors;\n    const metrics = discovery.metrics;\n\n    // Relevance scoring\n    let relevance = 30; // Base score\n    if (factors.hasWeb3Keywords) relevance += 25;\n    if (factors.hasAIKeywords) relevance += 20;\n    if (factors.hasSolanaKeywords) relevance += 15;\n    if (factors.hasEthereumKeywords) relevance += 10;\n    relevance = Math.min(100, relevance);\n\n    // Impact scoring based on metrics\n    let impact = 20;\n    const stars = metrics.stars ?? 0;\n    const engagement =\n      (metrics.points ?? 0) +\n      (metrics.likes ?? 0) +\n      (metrics.comments ?? 0) * 2;\n\n    if (stars > 1000) impact += 40;\n    else if (stars > 500) impact += 30;\n    else if (stars > 100) impact += 20;\n    else if (stars > 50) impact += 10;\n\n    if (engagement > 100) impact += 20;\n    impact = Math.min(100, impact);\n\n    // Effort scoring (higher = easier)\n    let effort = 50;\n    if (factors.hasTypeScript) effort += 20;\n    if (discovery.category === \"tooling\") effort += 15;\n    effort = Math.min(100, effort);\n\n    // Timing scoring\n    let timing = 40;\n    if (factors.recentActivity) timing += 30;\n    if (factors.highEngagement) timing += 30;\n    timing = Math.min(100, timing);\n\n    // Quality scoring\n    let quality = 40;\n    if (factors.hasTypeScript) quality += 20;\n    if (discovery.language) quality += 10;\n    if (discovery.description && discovery.description.length > 50) quality += 15;\n    quality = Math.min(100, quality);\n\n    const scores: DecisionScores = {\n      relevance,\n      impact,\n      effort,\n      timing,\n      quality,\n    };\n\n    const totalScore = Math.round(\n      relevance * SCORING_WEIGHTS.relevance +\n        impact * SCORING_WEIGHTS.impact +\n        effort * SCORING_WEIGHTS.effort +\n        timing * SCORING_WEIGHTS.timing +\n        quality * SCORING_WEIGHTS.quality\n    );\n\n    const recommendation: Recommendation =\n      totalScore >= 70\n        ? \"build\"\n        : totalScore >= 50\n          ? \"integrate\"\n          : totalScore >= 30\n            ? \"monitor\"\n            : \"ignore\";\n\n    return {\n      scores,\n      totalScore,\n      recommendation,\n      reasoning: \"Heuristic scoring (LLM unavailable)\",\n      summary: `${discovery.source} discovery with ${totalScore}/100 score`,\n      suggestedAction:\n        recommendation === \"build\"\n          ? \"Create gICM integration\"\n          : recommendation === \"integrate\"\n            ? \"Evaluate for integration\"\n            : recommendation === \"monitor\"\n              ? \"Add to watchlist\"\n              : \"No action needed\",\n      tags: discovery.tags,\n      riskLevel: totalScore < 30 ? \"low\" : totalScore < 60 ? \"medium\" : \"low\",\n      riskFactors:\n        totalScore < 50 ? [\"Low relevance\", \"Needs manual review\"] : [],\n      estimatedEffort: \"Unknown\",\n      confidence: 0.6, // Lower confidence for heuristic scoring\n    };\n  }\n}\n"],"mappings":";AAAA,SAAS,iBAAiB;;;ACA1B,SAAS,SAAS;AAGX,IAAM,uBAAuB,EAAE,OAAO;AAAA,EAC3C,WAAW,EAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,GAAG;AAAA,EACpC,QAAQ,EAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,GAAG;AAAA,EACjC,QAAQ,EAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,GAAG;AAAA;AAAA,EACjC,QAAQ,EAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,GAAG;AAAA,EACjC,SAAS,EAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,GAAG;AACpC,CAAC;AAIM,IAAM,uBAAuB,EAAE,KAAK,CAAC,WAAW,UAAU,UAAU,CAAC;AAGrE,IAAM,8BAA8B,EAAE,KAAK;AAAA,EAChD;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF,CAAC;AAGM,IAAM,0BAA0B,EAAE,OAAO;AAAA,EAC9C,SAAS;AAAA,EACT,WAAW,EAAE,OAAO;AACtB,CAAC;AAGM,IAAM,2BAA2B,EAAE,OAAO;AAAA,EAC/C,cAAc;AAAA,EACd,OAAO;AAAA,EACP,OAAO;AAAA,EACP,SAAS;AAAA,EACT,SAAS;AAAA,EACT,WAAW;AACb,CAAC;AAIM,IAAM,uBAAuB,EAAE,KAAK;AAAA,EACzC;AAAA;AAAA,EACA;AAAA;AAAA,EACA;AAAA;AAAA,EACA;AAAA;AACF,CAAC;AAIM,IAAM,uBAAuB,EAAE,OAAO;AAAA,EAC3C,QAAQ;AAAA,EACR,cAAc,yBAAyB,SAAS;AAAA,EAChD,YAAY,EAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,GAAG;AAAA,EACrC,gBAAgB;AAAA,EAChB,WAAW,EAAE,OAAO;AAAA,EACpB,SAAS,EAAE,OAAO;AAAA,EAClB,iBAAiB,EAAE,OAAO;AAAA,EAC1B,MAAM,EAAE,MAAM,EAAE,OAAO,CAAC;AAAA,EACxB,WAAW,EAAE,KAAK,CAAC,OAAO,UAAU,QAAQ,UAAU,CAAC;AAAA,EACvD,aAAa,EAAE,MAAM,EAAE,OAAO,CAAC;AAAA,EAC/B,iBAAiB,EAAE,OAAO;AAAA,EAC1B,YAAY,EAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC;AACrC,CAAC;AAUM,IAAM,qBAAyC;AAAA,EACpD,aAAa;AAAA,EACb,aAAa;AACf;AAMO,IAAM,4BAA4B,EAAE,OAAO;AAAA,EAChD,QAAQ,EAAE,OAAO;AAAA,IACf,WAAW,EAAE,OAAO;AAAA,MAClB,OAAO,EAAE,OAAO;AAAA,MAChB,WAAW,EAAE,OAAO;AAAA,IACtB,CAAC;AAAA,IACD,QAAQ,EAAE,OAAO;AAAA,MACf,OAAO,EAAE,OAAO;AAAA,MAChB,WAAW,EAAE,OAAO;AAAA,IACtB,CAAC;AAAA,IACD,QAAQ,EAAE,OAAO;AAAA,MACf,OAAO,EAAE,OAAO;AAAA,MAChB,WAAW,EAAE,OAAO;AAAA,IACtB,CAAC;AAAA,IACD,QAAQ,EAAE,OAAO;AAAA,MACf,OAAO,EAAE,OAAO;AAAA,MAChB,WAAW,EAAE,OAAO;AAAA,IACtB,CAAC;AAAA,IACD,SAAS,EAAE,OAAO;AAAA,MAChB,OAAO,EAAE,OAAO;AAAA,MAChB,WAAW,EAAE,OAAO;AAAA,IACtB,CAAC;AAAA,EACH,CAAC;AAAA,EACD,cAAc,yBAAyB,SAAS;AAAA,EAChD,YAAY,EAAE,OAAO;AAAA,EACrB,gBAAgB;AAAA,EAChB,WAAW,EAAE,OAAO;AAAA,EACpB,SAAS,EAAE,OAAO;AAAA,EAClB,iBAAiB,EAAE,OAAO;AAAA,EAC1B,MAAM,EAAE,MAAM,EAAE,OAAO,CAAC;AAAA,EACxB,WAAW,EAAE,KAAK,CAAC,OAAO,UAAU,QAAQ,UAAU,CAAC;AAAA,EACvD,aAAa,EAAE,MAAM,EAAE,OAAO,CAAC;AAAA,EAC/B,iBAAiB,EAAE,OAAO;AAAA,EAC1B,YAAY,EAAE,OAAO;AACvB,CAAC;AAIM,IAAM,kBAAkB;AAAA,EAC7B,WAAW;AAAA,EACX,QAAQ;AAAA,EACR,QAAQ;AAAA,EACR,QAAQ;AAAA,EACR,SAAS;AACX;;;AC7HO,IAAM,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAkEtB,SAAS,sBAAsB,WAAkC;AACtE,QAAM,aAAa,OAAO,QAAQ,UAAU,OAAO,EAChD,OAAO,CAAC,CAAC,EAAE,CAAC,MAAM,MAAM,MAAS,EACjC,IAAI,CAAC,CAAC,GAAG,CAAC,MAAM,GAAG,CAAC,KAAK,CAAC,EAAE,EAC5B,KAAK,IAAI;AAEZ,QAAM,aAAa,OAAO,QAAQ,UAAU,gBAAgB,EACzD,OAAO,CAAC,CAAC,EAAE,CAAC,MAAM,MAAM,IAAI,EAC5B,IAAI,CAAC,CAAC,CAAC,MAAM,EAAE,QAAQ,QAAQ,EAAE,EAAE,QAAQ,aAAa,EAAE,CAAC,EAC3D,KAAK,IAAI;AAEZ,SAAO;AAAA;AAAA,cAEK,UAAU,MAAM;AAAA,aACjB,UAAU,KAAK;AAAA,WACjB,UAAU,SAAS;AAAA,mBACX,UAAU,eAAe,gBAAgB;AAAA,cAC9C,UAAU,UAAU,SAAS;AAAA,gBAC3B,UAAU,YAAY,SAAS;AAAA,gBAC/B,UAAU,YAAY,SAAS;AAAA,YACnC,UAAU,KAAK,KAAK,IAAI,KAAK,MAAM;AAAA;AAAA;AAAA,EAG7C,cAAc,sBAAsB;AAAA;AAAA;AAAA,EAGpC,cAAc,eAAe;AAAA;AAAA,iBAEd,UAAU,aAAa,YAAY,KAAK,SAAS;AAAA,kBAChD,UAAU,aAAa,YAAY,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUtD;;;ACvFO,IAAM,iBAAN,MAAqB;AAAA,EAClB;AAAA,EACA;AAAA,EAER,YAAY,QAAsB;AAChC,SAAK,SAAS;AACd,SAAK,aAAa,OAAO,cAAc;AAAA,EACzC;AAAA,EAEA,MAAM,SAAS,WAAmD;AAChE,UAAM,SAAS,sBAAsB,SAAS;AAE9C,QAAI;AACF,YAAM,WAAW,MAAM,KAAK,QAAQ,MAAM;AAC1C,YAAM,SAAS,KAAK,cAAc,QAAQ;AAC1C,aAAO,KAAK,qBAAqB,MAAM;AAAA,IACzC,SAAS,OAAO;AAEd,cAAQ,KAAK,6DAA6D,KAAK;AAC/E,aAAO,KAAK,eAAe,SAAS;AAAA,IACtC;AAAA,EACF;AAAA,EAEA,MAAM,cACJ,aACsC;AACtC,UAAM,UAAU,oBAAI,IAA4B;AAGhD,UAAM,YAAY;AAClB,aAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK,WAAW;AACtD,YAAM,QAAQ,YAAY,MAAM,GAAG,IAAI,SAAS;AAChD,YAAM,cAAc,MAAM,QAAQ;AAAA,QAChC,MAAM,IAAI,CAAC,MAAM,KAAK,SAAS,CAAC,EAAE,KAAK,CAAC,MAAM,CAAC,EAAE,IAAI,CAAC,CAAU,CAAC;AAAA,MACnE;AAEA,iBAAW,CAAC,IAAI,MAAM,KAAK,aAAa;AACtC,gBAAQ,IAAI,IAAI,MAAM;AAAA,MACxB;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA,EAEA,gBAAgB,OAA+B;AAC7C,QAAI,SAAS,KAAK,WAAW,YAAa,QAAO;AACjD,QAAI,SAAS,KAAK,WAAW,YAAa,QAAO;AACjD,WAAO;AAAA,EACT;AAAA,EAEA,MAAc,QAAQ,QAAiC;AACrD,YAAQ,KAAK,OAAO,aAAa;AAAA,MAC/B,KAAK;AACH,eAAO,KAAK,WAAW,MAAM;AAAA,MAC/B,KAAK;AACH,eAAO,KAAK,cAAc,MAAM;AAAA,MAClC,KAAK;AACH,eAAO,KAAK,WAAW,MAAM;AAAA,MAC/B;AACE,cAAM,IAAI,MAAM,yBAAyB,KAAK,OAAO,WAAW,EAAE;AAAA,IACtE;AAAA,EACF;AAAA,EAEA,MAAc,WAAW,QAAiC;AACxD,UAAM,WAAW,MAAM,MAAM,8CAA8C;AAAA,MACzE,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,eAAe,UAAU,KAAK,OAAO,MAAM;AAAA,MAC7C;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,OAAO,KAAK,OAAO,SAAS;AAAA,QAC5B,UAAU;AAAA,UACR,EAAE,MAAM,UAAU,SAAS,cAAc;AAAA,UACzC,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,QAClC;AAAA,QACA,iBAAiB,EAAE,MAAM,cAAc;AAAA,QACvC,aAAa;AAAA,MACf,CAAC;AAAA,IACH,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,IAAI,MAAM,qBAAqB,SAAS,MAAM,EAAE;AAAA,IACxD;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AACjC,WAAO,KAAK,QAAQ,CAAC,GAAG,SAAS,WAAW;AAAA,EAC9C;AAAA,EAEA,MAAc,cAAc,QAAiC;AAC3D,UAAM,WAAW,MAAM,MAAM,yCAAyC;AAAA,MACpE,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,aAAa,KAAK,OAAO;AAAA,QACzB,qBAAqB;AAAA,MACvB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,OAAO,KAAK,OAAO,SAAS;AAAA,QAC5B,YAAY;AAAA,QACZ,QAAQ;AAAA,QACR,UAAU,CAAC,EAAE,MAAM,QAAQ,SAAS,OAAO,CAAC;AAAA,MAC9C,CAAC;AAAA,IACH,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,IAAI,MAAM,wBAAwB,SAAS,MAAM,EAAE;AAAA,IAC3D;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AACjC,WAAO,KAAK,QAAQ,CAAC,GAAG,QAAQ;AAAA,EAClC;AAAA,EAEA,MAAc,WAAW,QAAiC;AACxD,UAAM,QAAQ,KAAK,OAAO,SAAS;AACnC,UAAM,MAAM,2DAA2D,KAAK,wBAAwB,KAAK,OAAO,MAAM;AAEtH,UAAM,WAAW,MAAM,MAAM,KAAK;AAAA,MAChC,QAAQ;AAAA,MACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,MAC9C,MAAM,KAAK,UAAU;AAAA,QACnB,UAAU;AAAA,UACR;AAAA,YACE,OAAO,CAAC,EAAE,MAAM,GAAG,aAAa;AAAA;AAAA,EAAO,MAAM,GAAG,CAAC;AAAA,UACnD;AAAA,QACF;AAAA,QACA,kBAAkB;AAAA,UAChB,aAAa;AAAA,UACb,kBAAkB;AAAA,QACpB;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,IAAI,MAAM,qBAAqB,SAAS,MAAM,EAAE;AAAA,IACxD;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AACjC,WAAO,KAAK,WAAW,CAAC,GAAG,SAAS,MAAM,CAAC,GAAG,QAAQ;AAAA,EACxD;AAAA,EAEQ,cAAc,UAAkC;AAEtD,QAAI,UAAU;AAGd,UAAM,iBAAiB,SAAS,MAAM,8BAA8B;AACpE,QAAI,gBAAgB;AAClB,gBAAU,eAAe,CAAC,EAAE,KAAK;AAAA,IACnC;AAGA,UAAM,YAAY,QAAQ,MAAM,aAAa;AAC7C,QAAI,WAAW;AACb,gBAAU,UAAU,CAAC;AAAA,IACvB;AAEA,UAAM,SAAS,KAAK,MAAM,OAAO;AACjC,UAAM,YAAY,0BAA0B,MAAM,MAAM;AAExD,WAAO;AAAA,MACL,QAAQ;AAAA,QACN,WAAW,UAAU,OAAO,UAAU;AAAA,QACtC,QAAQ,UAAU,OAAO,OAAO;AAAA,QAChC,QAAQ,UAAU,OAAO,OAAO;AAAA,QAChC,QAAQ,UAAU,OAAO,OAAO;AAAA,QAChC,SAAS,UAAU,OAAO,QAAQ;AAAA,MACpC;AAAA,MACA,cAAc,UAAU;AAAA,MACxB,YAAY,UAAU;AAAA,MACtB,gBAAgB,UAAU;AAAA,MAC1B,WAAW,UAAU;AAAA,MACrB,SAAS,UAAU;AAAA,MACnB,iBAAiB,UAAU;AAAA,MAC3B,MAAM,UAAU;AAAA,MAChB,WAAW,UAAU;AAAA,MACrB,aAAa,UAAU;AAAA,MACvB,iBAAiB,UAAU;AAAA,MAC3B,YAAY,UAAU;AAAA,IACxB;AAAA,EACF;AAAA,EAEQ,qBAAqB,QAAwC;AAEnE,UAAM,kBACJ,OAAO,OAAO,YAAY,gBAAgB,YAC1C,OAAO,OAAO,SAAS,gBAAgB,SACvC,OAAO,OAAO,SAAS,gBAAgB,SACvC,OAAO,OAAO,SAAS,gBAAgB,SACvC,OAAO,OAAO,UAAU,gBAAgB;AAG1C,UAAM,kBAAkB,KAAK;AAAA,OAC1B,OAAO,aAAa,mBAAmB;AAAA,IAC1C;AAEA,WAAO;AAAA,MACL,GAAG;AAAA,MACH,YAAY,KAAK,IAAI,KAAK,KAAK,IAAI,GAAG,eAAe,CAAC;AAAA,IACxD;AAAA,EACF;AAAA;AAAA,EAGQ,eAAe,WAA0C;AAC/D,UAAM,UAAU,UAAU;AAC1B,UAAM,UAAU,UAAU;AAG1B,QAAI,YAAY;AAChB,QAAI,QAAQ,gBAAiB,cAAa;AAC1C,QAAI,QAAQ,cAAe,cAAa;AACxC,QAAI,QAAQ,kBAAmB,cAAa;AAC5C,QAAI,QAAQ,oBAAqB,cAAa;AAC9C,gBAAY,KAAK,IAAI,KAAK,SAAS;AAGnC,QAAI,SAAS;AACb,UAAM,QAAQ,QAAQ,SAAS;AAC/B,UAAM,cACH,QAAQ,UAAU,MAClB,QAAQ,SAAS,MACjB,QAAQ,YAAY,KAAK;AAE5B,QAAI,QAAQ,IAAM,WAAU;AAAA,aACnB,QAAQ,IAAK,WAAU;AAAA,aACvB,QAAQ,IAAK,WAAU;AAAA,aACvB,QAAQ,GAAI,WAAU;AAE/B,QAAI,aAAa,IAAK,WAAU;AAChC,aAAS,KAAK,IAAI,KAAK,MAAM;AAG7B,QAAI,SAAS;AACb,QAAI,QAAQ,cAAe,WAAU;AACrC,QAAI,UAAU,aAAa,UAAW,WAAU;AAChD,aAAS,KAAK,IAAI,KAAK,MAAM;AAG7B,QAAI,SAAS;AACb,QAAI,QAAQ,eAAgB,WAAU;AACtC,QAAI,QAAQ,eAAgB,WAAU;AACtC,aAAS,KAAK,IAAI,KAAK,MAAM;AAG7B,QAAI,UAAU;AACd,QAAI,QAAQ,cAAe,YAAW;AACtC,QAAI,UAAU,SAAU,YAAW;AACnC,QAAI,UAAU,eAAe,UAAU,YAAY,SAAS,GAAI,YAAW;AAC3E,cAAU,KAAK,IAAI,KAAK,OAAO;AAE/B,UAAM,SAAyB;AAAA,MAC7B;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAEA,UAAM,aAAa,KAAK;AAAA,MACtB,YAAY,gBAAgB,YAC1B,SAAS,gBAAgB,SACzB,SAAS,gBAAgB,SACzB,SAAS,gBAAgB,SACzB,UAAU,gBAAgB;AAAA,IAC9B;AAEA,UAAM,iBACJ,cAAc,KACV,UACA,cAAc,KACZ,cACA,cAAc,KACZ,YACA;AAEV,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA;AAAA,MACA,WAAW;AAAA,MACX,SAAS,GAAG,UAAU,MAAM,mBAAmB,UAAU;AAAA,MACzD,iBACE,mBAAmB,UACf,4BACA,mBAAmB,cACjB,6BACA,mBAAmB,YACjB,qBACA;AAAA,MACV,MAAM,UAAU;AAAA,MAChB,WAAW,aAAa,KAAK,QAAQ,aAAa,KAAK,WAAW;AAAA,MAClE,aACE,aAAa,KAAK,CAAC,iBAAiB,qBAAqB,IAAI,CAAC;AAAA,MAChE,iBAAiB;AAAA,MACjB,YAAY;AAAA;AAAA,IACd;AAAA,EACF;AACF;;;AHpSO,IAAM,gBAAN,cAA4B,UAAU;AAAA,EACnC;AAAA,EACA;AAAA,EACA;AAAA,EAER,YAAY,QAA6B;AACvC,UAAM,YAAY,MAAM;AAExB,SAAK,aAAa,OAAO,cAAc;AACvC,SAAK,aAAa,OAAO;AAEzB,UAAM,eAA6B;AAAA,MACjC,aAAa,OAAO;AAAA,MACpB,QAAQ,OAAO;AAAA,MACf,OAAO,OAAO;AAAA,MACd,YAAY,KAAK;AAAA,IACnB;AAEA,SAAK,SAAS,IAAI,eAAe,YAAY;AAAA,EAC/C;AAAA,EAEA,kBAA0B;AACxB,WAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAOgB,KAAK,WAAW,WAAW;AAAA,qCACjB,KAAK,WAAW,WAAW;AAAA,yBACvC,KAAK,WAAW,WAAW;AAAA,EAClD;AAAA,EAEA,MAAM,QAAQ,SAA6C;AACzD,UAAM,SAAS,QAAQ,UAAU;AAEjC,YAAQ,QAAQ;AAAA,MACd,KAAK;AACH,eAAO,KAAK,kBAAkB,QAAQ,QAAQ,SAA0B;AAAA,MAE1E,KAAK;AACH,eAAO,KAAK,cAAc,QAAQ,QAAQ,WAA8B;AAAA,MAE1E,KAAK;AACH,eAAO,KAAK;AAAA,UACV;AAAA,UACA;AAAA,YACE,YAAY,KAAK;AAAA,YACjB,UAAW,KAAK,OAA+B;AAAA,UACjD;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,MAEF;AACE,eAAO,KAAK,aAAa,OAAO,MAAM,mBAAmB,MAAM,EAAE;AAAA,IACrE;AAAA,EACF;AAAA,EAEA,MAAM,SAAS,WAAoD;AACjE,SAAK,IAAI,eAAe,UAAU,KAAK,EAAE;AAEzC,UAAM,SAAS,MAAM,KAAK,OAAO,SAAS,SAAS;AACnD,UAAM,SAAS,KAAK,OAAO,gBAAgB,OAAO,UAAU;AAE5D,SAAK;AAAA,MACH,UAAU,OAAO,UAAU,kBAAkB,MAAM,sBAAsB,OAAO,cAAc;AAAA,IAChG;AAGA,QAAI,KAAK,YAAY;AACnB,YAAM,KAAK,WAAW,WAAW,QAAQ,MAAM;AAAA,IACjD;AAEA,WAAO,EAAE,WAAW,QAAQ,OAAO;AAAA,EACrC;AAAA,EAEA,MAAM,aAAa,aAA0D;AAC3E,SAAK,IAAI,cAAc,YAAY,MAAM,cAAc;AAEvD,UAAM,UAA6B,CAAC;AAEpC,eAAW,aAAa,aAAa;AACnC,YAAM,SAAS,MAAM,KAAK,SAAS,SAAS;AAC5C,cAAQ,KAAK,MAAM;AAAA,IACrB;AAGA,YAAQ,KAAK,CAAC,GAAG,MAAM,EAAE,OAAO,aAAa,EAAE,OAAO,UAAU;AAEhE,UAAM,WAAW,QAAQ,OAAO,CAAC,MAAM,EAAE,WAAW,cAAc,EAAE;AACpE,UAAM,SAAS,QAAQ,OAAO,CAAC,MAAM,EAAE,WAAW,cAAc,EAAE;AAClE,UAAM,WAAW,QAAQ,OAAO,CAAC,MAAM,EAAE,WAAW,QAAQ,EAAE;AAE9D,SAAK;AAAA,MACH,YAAY,QAAQ,mBAAmB,MAAM,gBAAgB,QAAQ;AAAA,IACvE;AAEA,WAAO;AAAA,EACT;AAAA,EAEA,MAAc,kBACZ,WACsB;AACtB,QAAI,CAAC,WAAW;AACd,aAAO,KAAK,aAAa,OAAO,MAAM,uBAAuB;AAAA,IAC/D;AAEA,QAAI;AACF,YAAM,SAAS,MAAM,KAAK,SAAS,SAAS;AAE5C,aAAO,KAAK;AAAA,QACV;AAAA,QACA;AAAA,QACA;AAAA,QACA,OAAO,OAAO;AAAA,QACd,cAAc,UAAU,KAAK,MAAM,OAAO,OAAO,UAAU,SAAS,OAAO,MAAM;AAAA,MACnF;AAAA,IACF,SAAS,OAAO;AACd,YAAM,UAAU,iBAAiB,QAAQ,MAAM,UAAU;AACzD,aAAO,KAAK,aAAa,OAAO,MAAM,OAAO;AAAA,IAC/C;AAAA,EACF;AAAA,EAEA,MAAc,cACZ,aACsB;AACtB,QAAI,CAAC,eAAe,YAAY,WAAW,GAAG;AAC5C,aAAO,KAAK,aAAa,OAAO,MAAM,yBAAyB;AAAA,IACjE;AAEA,QAAI;AACF,YAAM,UAAU,MAAM,KAAK,aAAa,WAAW;AAEnD,YAAM,UAAU;AAAA,QACd,OAAO,QAAQ;AAAA,QACf,cAAc,QAAQ,OAAO,CAAC,MAAM,EAAE,WAAW,cAAc;AAAA,QAC/D,WAAW,QAAQ,OAAO,CAAC,MAAM,EAAE,WAAW,cAAc;AAAA,QAC5D,UAAU,QAAQ,OAAO,CAAC,MAAM,EAAE,WAAW,QAAQ;AAAA,QACrD,gBAAgB,QAAQ,MAAM,GAAG,CAAC;AAAA,MACpC;AAEA,aAAO,KAAK;AAAA,QACV;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA,aAAa,QAAQ,MAAM,iBAAiB,QAAQ,aAAa,MAAM,mBAAmB,QAAQ,UAAU,MAAM;AAAA,MACpH;AAAA,IACF,SAAS,OAAO;AACd,YAAM,UAAU,iBAAiB,QAAQ,MAAM,UAAU;AACzD,aAAO,KAAK,aAAa,OAAO,MAAM,OAAO;AAAA,IAC/C;AAAA,EACF;AAAA;AAAA,EAGA,gBAAgB,SAA+C;AAC7D,WAAO,QAAQ,OAAO,CAAC,MAAM,EAAE,WAAW,cAAc;AAAA,EAC1D;AAAA,EAEA,aAAa,SAA+C;AAC1D,WAAO,QAAQ,OAAO,CAAC,MAAM,EAAE,WAAW,cAAc;AAAA,EAC1D;AAAA,EAEA,YAAY,SAA+C;AACzD,WAAO,QAAQ,OAAO,CAAC,MAAM,EAAE,WAAW,QAAQ;AAAA,EACpD;AAAA;AAAA,EAGA,cAAc,YAA+C;AAC3D,SAAK,aAAa,EAAE,GAAG,KAAK,YAAY,GAAG,WAAW;AACtD,SAAK,IAAI,uBAAuB,KAAK,UAAU,KAAK,UAAU,CAAC,EAAE;AAAA,EACnE;AACF;","names":[]}